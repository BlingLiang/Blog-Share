---
layout:     post
title:      "用pyhton求N以内的素数个数"
date:       2019-11-6
author:     "唐一川"
header-img: ""
tags:
    - python
    - 用numpy实现“筛法”
---

​		求N以内的素数个数，这个问题之前用C语言就粗劣写过，最近学了python的numpy库和切片操作后，又对这个问题产生了求解的想法，在多次调试的过程中时间效率有了大幅度提高——目前处理10,000,000以内的素数个数用时不到3s。

## 基本思路

> 思路1.基于素数定义，对于每个上限(upper)以内的数，遍历比其本身小的素数进行求余数，若存在余数为0则不是素数。

> 思路2.采用筛法，以2为起点，筛去所有2的倍数，再以筛完后的首个数再次筛去倍数，直到首个数大于上限(upper)的平方根为止。



## 代码实现



### 1.最笨拙的算法！

​		先用最原始的思路1进行求解，运行find_prime_1.py，找出1,000,000以内的素数，用时约3秒钟。但只要稍微加大上限，基本run的时间就难以等待了。

##### find_prime_1.py

```python
# -*- coding: utf-8 -*-
# @Time : 2019/11/5 21:43
# @Author : YiChuan
# @File : find_prime_1.py
import time
from math import sqrt


def find_prime(upper):
    prime_list = list()  # 存放找到的质数
    for i in range(2, upper):
        flag = True
        for p in prime_list:  # 遍历当前已经找到的质数列表
            if i % p == 0:
                flag = False
                break
            elif p > sqrt(i):
                break
        if flag:
            prime_list.append(i)
    return prime_list


upper = 1000000
t0 = time.time()
prime_list = find_prime(upper)
t1 = time.time()
print("查找%d以内的质数耗时%0.3f秒，共找到%d个质数" % (upper, t1 - t0, len(prime_list)))

```



### 2.进阶筛法进行求解，速度提升！！

​		下面这个 find_prime_2.py 的代码，引入了numpy这个科学计算库，采用筛法筛去所有合数，速度提高。找出 10,000,000 以内的质数只需要12秒，当然，如果把这个数字扩大十倍换成 100,000,000 ，时间将会飞速增长，等待时间过于漫长。

##### find_prime_2.py

```python
# -*- coding: utf-8 -*-
# @Time : 2019/11/5 21:47
# @Author : YiChuan
# @File : find_prime_2.py
import time
import numpy as np


def find_prime(upper):
    prime_list = list()
    middle = int(np.sqrt(upper))
    nums = np.arange(upper)
    nums[1] = 0  # 寻找质数从2开始，元素置零以表示不是质数

    while True:
        primes = nums[nums > 0]
        if primes.any():
            p = primes[0]
            prime_list.append(p)  # 保存第一个元素到返回的数组
            nums[p::p] = 0  # 这个质数的所有倍数(包括本身)，都置为0（表示非质数）
            if p > middle:
                break
        else:
            break
    # 当退出循环后，无论是由于全为0还是找到的质数已经大于上限的平方根
    # nums里面剩余的非0元素，都是质数，合并到返回的数组中
    prime_list.extend(nums[nums > 0].tolist())
    return prime_list


upper = 10000000
t0 = time.time()
prime_list = find_prime(upper)
t1 = time.time()
print(prime_list[-1])
print('查找%d以内的质数耗时%0.3f秒，共找到%d个质数' % (upper, t1 - t0, len(prime_list)))
```



### 3.分块优化配合筛法，速度大幅度提升！！！

​		经过分析发现，numpy 的 ndarray 对象，其元素数量超过一定范围后，效率明显变慢。针对这一点，进行分块优化后运行 find_prime_3.py，找出1亿以内的质数，耗时不到3秒钟！ 

##### find_prime_3.py

```python
# -*- coding: utf-8 -*-
# @Time : 2019/11/5 22:22
# @Author : YiChuan
# @File : find_prime_3.py
import time
import numpy as np


def find_prime(upper):
    prime_list = list()
    mid = int(np.sqrt(upper))
    nums = np.arange(upper)
    nums[1] = 0
    while True:
        primes = nums[nums > 0]
        if primes.any():
            p = primes[0]
            prime_list.append(p)
            nums[p::p] = 0
            if p > mid:
                break
        else:
            break
    prime_list.extend(nums[nums > 0].tolist())
    return prime_list


def fast_find_prime(upper, base=100000, block=20000000):
    if upper <= base:
        return find_prime(upper)
    mid = int(np.sqrt(upper))
    prime_list = find_prime(base)
    prime_array = np.array(prime_list)
    prime_array = prime_array[prime_array <= mid]
    start = base
    while start < upper:
        end = start + block
        if end > upper:
            end = upper
        print("\r正在搜索区间({0},{1})".format(start, end), end='', flush=True)
        prime_list.extend(process_func(np.copy(prime_array), (start, end)))
        start += block
    return prime_list


def process_func(primes, task_range):
    # primes 用以剔除非质数的已有质数表
    # task_range  分块任务的数值范围
    
    nums = np.arange(task_range[0], task_range[1])
    for p in primes:
        # 得到区间中第一个p的倍数的数的下标k
        k = (p - task_range[0] % p) % p
        nums[k::p] = 0
    return nums[nums > 0].tolist()


upper = 100000000
t0 = time.time()
prime_list = fast_find_prime(upper)
t1 = time.time()
print("\n查找%d以内的质数耗时%0.3f秒，共找到%d个质数" % (upper, t1 - t0, len(prime_list)))
```



## 一点多余思考

>对素数进行深入思考，不难发现，大于3的所有的素数都应满足 6n+1 或 6n-1 的形式，这样来重新定义原始数组应当会更节省存储空间。但是随之而来的问题是——数n和下标k的对应关系变得不再那么清晰，需要重新思考。

>在进行合数置零的环节中，同一个数可能被置零很多次，比如15，在取出3和5之前都被进行置零，更大的数字置零次数也会相应大幅度增加，是否可以设计优化改进减少置零次数以提高速度，当然，这也和numpy切片操作的底层实现原理有关。

>在解决问题过程中，搜索到的利用C语言求解这个问题的代码速度会很快，不同的算法真的是一个比一个强，千亿数据5秒内可运算结束。虽然确实理论上C语言更加底层，速度快是必然，但这些算法是否可以在python里如法炮制，我觉得是可以尝试的。



## 参考资料

①	[3秒钟内统计出小于1亿的素数个数]( https://blog.csdn.net/xufive/article/details/102892049 )

②	[半秒内筛一亿以内的所有素数]( https://blog.csdn.net/controlfate/article/details/6758202 )
